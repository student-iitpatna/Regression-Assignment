{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5e6749-4046-42de-b2e2-237f8e9a02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.What is simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65efe6f6-6155-499f-b0a2-7bbbab0ba972",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Simple linear regression is a statistical method used to model the relationship between two variables by fitting a linear equation to observed data. It assumes that one variable (the dependent variable) is dependent on the other variable (the independent variable). The goal is to find the best-fitting straight line (a linear relationship) through the data points.\n",
    "\n",
    "The equation for simple linear regression is:\n",
    "\n",
    "𝑦=𝛽0 + 𝛽1𝑥 + 𝜖\n",
    "\n",
    "Where:\n",
    "y is the dependent variable (the variable being predicted),\n",
    "x is the independent variable (the predictor),\n",
    "β0is the y-intercept of the line (where the line crosses the y-axis),\n",
    "β1is the slope of the line (how much \n",
    "y changes for a one-unit change in x),\n",
    "ϵ represents the error term (the difference between the predicted and actual values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6f5157-cc08-4bf4-a716-7fd1f03a0a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. What are the key assumptions of Simple Linear Regression\u001d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07f3136-c1e8-407e-8b39-765347caadc5",
   "metadata": {},
   "source": [
    "Answer:\n",
    "The key assumptions of simple linear regressions are:\n",
    "\n",
    "Linearity:\n",
    "The relationship between the independent variable (x) and the dependent variable (y) is linear. This means that changes in y are proportional to changes in x.\n",
    "\n",
    "Independence:\n",
    "The observations are independent of each other. This assumption is important for ensuring that the model doesn't become biased due to correlation between data points (for example, in time series data).\n",
    "\n",
    "Homoscedasticity:\n",
    "The variance of the residuals (errors) is constant across all levels of the independent variable (x). This means that the spread or variability of the errors is the same for all values of x. If this assumption is violated (heteroscedasticity), it can lead to unreliable estimates and statistical tests.\n",
    "\n",
    "Normality of Errors:\n",
    "The residuals (errors) are assumed to be normally distributed. This assumption is particularly important for hypothesis testing and creating confidence intervals. It is less important for prediction, but violations can affect the validity of statistical inference.\n",
    "\n",
    "No Perfect Multicollinearity:\n",
    "Since simple linear regression only involves one independent variable, this assumption is automatically met. However, in multiple regression (with more than one predictor), there should not be perfect correlation between predictors, as it can cause issues with estimating the coefficients.\n",
    "\n",
    "No Autocorrelation:\n",
    "The residuals should not be correlated with one another. This is particularly important in time series data, where autocorrelation could occur if the residuals from one time period are correlated with residuals from another time period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d33f59-ac24-436a-ae6f-85bce5243f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "3- What does the coefficient m represent in the equation Y=mX+c ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bed9ec-c18f-42cd-b700-330ee44734f9",
   "metadata": {},
   "source": [
    "Answer:\n",
    "In the equation 𝑌=𝑚𝑋+𝑐, which represents a straight-line equation (or simple linear regression model), the coefficient m represents the slope of the line.\n",
    "\n",
    "Specifically, m indicates how much the dependent variable Y changes for a one-unit change in the independent variable X. In other words, it quantifies the rate of change or the relationship between \n",
    "x and Y.\n",
    "\n",
    "Interpretation of m:\n",
    "If m>0, the relationship between X and Y is positive, meaning as X increases, Y also increases.\n",
    "If m<0, the relationship is negative, meaning as X increases, Y decreases.\n",
    "If m=0, there is no linear relationship between X and Y, and Y remains constant regardless of changes in X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c4d36-920c-4785-8269-04b61b21a16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "4- What does the intercept c represent in the equation Y=mX+c ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bf4521-e7f4-46b8-97eb-fda945c1a302",
   "metadata": {},
   "source": [
    "Answer\n",
    "In the equation Y=mX+c, the intercept c represents the y-intercept of the line. It is the value of the dependent variable Y when the independent variable \n",
    "X is equal to zero.\n",
    "\n",
    "Interpretation of c:\n",
    "The intercept c gives the starting value of Y when X=0. It shows where the line crosses the y-axis.\n",
    "In a practical context, it often represents the baseline value of the dependent variable when no influence from the independent variable is present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845d370-4176-4565-bf27-9b53aacfbb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. How do we calculate the slope m in Simple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353bf87d-bf64-4463-9989-9d82922b1bd6",
   "metadata": {},
   "source": [
    "Answer\n",
    "In Simple Linear Regression, the slope m (also called the regression coefficient) represents the change in the dependent variable Y for a one-unit change in the independent variable X. To calculate the slope m, you use the following formula:\n",
    "\n",
    "𝑚 =∑(𝑋𝑖−𝑋ˉ)(𝑌𝑖−𝑌ˉ)/∑(𝑋𝑖−𝑋ˉ)2\n",
    "\n",
    "​Where:\n",
    "𝑋𝑖 and Yi are the individual data points for the independent and dependent variables, respectively.\n",
    "Xˉand Yˉare the means (averages) of the independent and dependent variables, respectively.\n",
    "The summations run over all the data points in your dataset.\n",
    "u the rate at which \\( Y \\) changes with respect to \\( X \\)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ae45ce-0af7-4c77-884c-e1b39a31a99c",
   "metadata": {},
   "source": [
    "6. What is the purpose of the least squares method in Simple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a653b6-91a8-4196-8a9a-5a1b8f5fc1ae",
   "metadata": {},
   "source": [
    "Answer:\n",
    "The purpose of the least squares method in Simple Linear Regression is to find the best-fitting line (also called the regression line) that minimizes the differences between the observed data points and the predicted values from the model.\n",
    "\n",
    "In other words, it seeks to minimize the sum of the squared differences (or residuals) between the actual values of the dependent variable (Y) and the values predicted by the linear equation (Y=mX+c).\n",
    "\n",
    "How the Least Squares Method Works:\n",
    "Residuals:\n",
    "The residual for each data point is the difference between the actual value (Yi) and the predicted value from the line (Y^i). The residual for the i-th data point is:\n",
    "ei =Yi − Y^i\n",
    "​\n",
    " \n",
    "Where \n",
    "Y^i =mXi +c is the predicted value for that data point.\n",
    "\n",
    "Minimizing the Sum of Squared Residuals:\n",
    "The least squares method aims to minimize the sum of the squared residuals (SSR), which is calculated as:\n",
    "\n",
    "\n",
    "SSR=∑(Yi − Y^i)2\n",
    " \n",
    "Squaring the residuals ensures that both positive and negative errors contribute positively to the total, and it penalizes larger deviations more heavily.\n",
    "\n",
    "Best-Fitting Line:\n",
    "By minimizing this sum of squared residuals, the least squares method finds the values of the slope \n",
    "m and the intercept c that make the regression line the best fit for the data. This means the line that has the smallest possible errors, on average, in predicting Y from X.\n",
    "\n",
    "Why Least Squares?\n",
    "Efficiency: The least squares method is mathematically simple and computationally efficient. It provides a straightforward way to estimate the parameters of a linear regression model.\n",
    "Optimality: The least squares estimates are unbiased and consistent under the assumptions of the linear regression model (such as independence of errors and homoscedasticity). This means, on average, the estimates of the slope and intercept are correct and will converge to the true values as the sample size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4afdc37-7348-44be-8390-5e76e5bf7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "7.How is the coefficient of determination (R²) interpreted in Simple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a34a184-1518-4bcf-a11a-9d16d4d1578c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "The coefficient of determination, commonly denoted as R2, is a key statistical measure used to assess how well the linear regression model explains the variability in the dependent variable (Y) based on the independent variable (X).\n",
    "\n",
    "Interpretation of R2:\n",
    "Proportion of Variance Explained:\n",
    "R2represents the proportion of the total variance in the dependent variable Y that is explained by the independent variable X in the model. It is calculated as the square of the correlation coefficient between X and Y.\n",
    "\n",
    "Mathematically, it is defined as:\n",
    "R2 =1− ∑(Yi − Yˉ)2 /∑(Yi − Y^i)2\n",
    " \n",
    "​\n",
    " \n",
    "Where:\n",
    "Yi are the observed values of Y,\n",
    "Y^iare the predicted values from the regression model,\n",
    "Yˉis the mean of the observed values of Y,\n",
    "The numerator represents the sum of squared residuals (SSR), or the error between the observed and predicted values.\n",
    "The denominator represents the total sum of squares (TSS), or the total variability of Y around its mean.\n",
    "Range of R2:\n",
    "The value of R2 ranges from 0 to 1:\n",
    "R2=0 means that the independent variable X does not explain any of the variability in Y — the regression model is a poor fit.\n",
    "R2=1 means that the independent variable X explains all of the variability in Y — the model perfectly fits the data.\n",
    "Intermediate values of R2 indicate varying levels of explanatory power. For example, an R2 value of 0.75 means that 75% of the variability in Y is explained by X, while 25% of the variability is unexplained or due to factors not included in the model.\n",
    "Goodness of Fit:\n",
    "A higher R2 value generally indicates a better fit of the model, meaning the regression line explains a greater proportion of the variance in the dependent variable.\n",
    "A lower R2value suggests that the model does not explain much of the variation in Y, and other factors might be influencing Y that are not accounted for by X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19d2002-604b-4b22-9d9a-d33cbc7191a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "8.What is Multiple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfcd692-789e-4b58-b5f0-a3eae2ac03ae",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Multiple Linear Regression is an extension of simple linear regression that models the relationship between a dependent variable (Y) and two or more independent variables (\n",
    "𝑋1,𝑋2,…,𝑋𝑝). Unlike simple linear regression, which only involves one independent variable, multiple linear regression can handle multiple predictors to explain the variation in the dependent variable.\n",
    "The Equation for Multiple Linear Regression:\n",
    "The equation for multiple linear regression is:\n",
    "Y=β0+β1X1+β2X2+⋯+βpXp+ϵ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5f48ef-2069-4be7-a898-969bdcd66a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "9.What is the main difference between Simple and Multiple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776522ec-b2aa-449f-8f8a-22349223506f",
   "metadata": {},
   "source": [
    "Answer\n",
    "The main difference between Simple Linear Regression and Multiple Linear Regression lies in the number of independent variables (predictors) used to predict the dependent variable.\n",
    "\n",
    "Key Differences:\n",
    "Number of Predictors (Independent Variables):\n",
    "Simple Linear Regression: Involves one independent variable to predict the dependent variable.\n",
    "Example: Predicting house price based on just the size of the house.\n",
    "Equation: Y=β0 +β1X+ϵ\n",
    "Multiple Linear Regression: Involves two or more independent variables to predict the dependent variable.\n",
    "Example: Predicting house price based on size, location, and number of bedrooms.\n",
    "Equation: \n",
    "Y=β0+β1X1+β2X2+⋯+βpXp +ϵ\n",
    "\n",
    "Complexity of the Model:\n",
    "Simple Linear Regression: The model is simpler, as it only considers a single predictor variable.\n",
    "Multiple Linear Regression: The model is more complex, as it simultaneously accounts for multiple predictors and their relationship with the dependent variable.\n",
    "\n",
    "Interpretation of Coefficients:\n",
    "Simple Linear Regression: The slope β1represents how much the dependent variable Y changes with a one-unit change in the independent variable X.\n",
    "Multiple Linear Regression: Each coefficient β1,β2,…,βp represents how much the dependent variable Y changes with a one-unit change in the corresponding independent variable, while holding all other predictors constant.\n",
    "\n",
    "Model Purpose:\n",
    "Simple Linear Regression: Used to analyze and predict the relationship between two variables, typically when the relationship is expected to be linear.\n",
    "Multiple Linear Regression: Used to analyze and predict outcomes based on the influence of several variables simultaneously, providing a more comprehensive model when multiple factors are involved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924b46f-d8c6-40d8-909f-0ef9e3ba86db",
   "metadata": {},
   "outputs": [],
   "source": [
    "10.What are the key assumptions of Multiple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac766c0f-53b8-4533-8db9-52147796984c",
   "metadata": {},
   "source": [
    "Answer:\n",
    "In Multiple Linear Regression (MLR), there are several key assumptions that must be met for the model to produce reliable results. These assumptions are:\n",
    "\n",
    "Linearity: The relationship between the independent variables (predictors) and the dependent variable is assumed to be linear. This means that the effect of each predictor on the dependent variable is constant and additive.\n",
    "\n",
    "Independence of Errors: The residuals (errors) of the model must be independent of each other. This implies that there should be no correlation between the residuals at any two data points. Violating this assumption often occurs when there is autocorrelation, such as in time series data.\n",
    "\n",
    "Homoscedasticity: The variance of the errors (residuals) should be constant across all levels of the independent variables. In other words, the spread of residuals should be roughly the same for all predicted values of the dependent variable. This assumption can be checked by plotting the residuals against the fitted values.\n",
    "\n",
    "Normality of Errors: The residuals (errors) of the model should be approximately normally distributed. This assumption is important for conducting valid hypothesis tests (e.g., t-tests, F-tests). It can be checked using plots like Q-Q plots or statistical tests for normality.\n",
    "\n",
    "No Multicollinearity: The independent variables should not be highly correlated with each other. High correlation between independent variables (multicollinearity) can make it difficult to estimate the unique contribution of each predictor to the model. This can be checked using metrics like the Variance Inflation Factor (VIF).\n",
    "\n",
    "No Measurement Error in Predictors: The model assumes that the independent variables are measured without error. If the predictors are measured with error, it can lead to biased and inconsistent parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3732068f-5c8a-411b-ad6b-cce9c9a9dfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. What is heteroscedasticity, and how does it affect the results of a Multiple Linear Regression model\u001d",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e275bff2-a452-422c-a1fd-8aedcb4089d1",
   "metadata": {},
   "source": [
    "Answer:\n",
    "Heteroscedasticity refers to the condition where the variance of the errors (residuals) in a regression model is not constant across all levels of the independent variables. In other words, the spread or variability of the residuals changes as the predicted values of the dependent variable change. This violates the homoscedasticity assumption, which states that the variance of residuals should remain constant for all values of the independent variables.\n",
    "\n",
    "Effects of Heteroscedasticity on Multiple Linear Regression Results:\n",
    "When heteroscedasticity is present in a Multiple Linear Regression (MLR) model, it can affect the results in the following ways:\n",
    "\n",
    "Bias in Standard Errors:\n",
    "Heteroscedasticity leads to inefficient estimation of the coefficients. While the regression coefficients themselves (slopes and intercept) remain unbiased, the standard errors of these coefficients may be biased.\n",
    "As a result, hypothesis tests (e.g., t-tests for individual coefficients) and confidence intervals become unreliable because they are based on incorrect standard errors. This could lead to incorrect conclusions about the significance of predictors.\n",
    "\n",
    "Incorrect Significance Tests:\n",
    "The biased standard errors can lead to incorrect p-values in hypothesis tests. This increases the risk of Type I (false positive) or Type II (false negative) errors, meaning you may either wrongly conclude that a predictor is significant or fail to detect a significant relationship.\n",
    "\n",
    "Inefficiency in Model Estimation:\n",
    "While the estimates of the coefficients are still unbiased, they are not efficient. This means that the Ordinary Least Squares (OLS) estimates do not have the smallest possible variance compared to other estimators, such as Generalized Least Squares (GLS), which can better handle heteroscedasticity.\n",
    "\n",
    "Invalid Inferences:\n",
    "Because the p-values and confidence intervals derived from biased standard errors are unreliable, making inferences about the relationships between predictors and the outcome can be misleading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cb73fe-c61b-4fa6-be2e-ea94b211fd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "12.How can you improve a Multiple Linear Regression model with high multicollinearity ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8bcd6a-d8a7-460c-946a-4325e14be470",
   "metadata": {},
   "source": [
    "Answer:\n",
    "To improve a Multiple Linear Regression model with high multicollinearity, you can consider the following strategies:\n",
    "\n",
    "1. Remove One of the Correlated Variables\n",
    "If two or more predictors are highly correlated (e.g., correlation coefficient above 0.7 or 0.8), consider removing one of them. This will reduce redundancy and help mitigate multicollinearity.\n",
    "This approach is particularly useful if the correlated variables are conceptually redundant or if they have a similar impact on the dependent variable.\n",
    "\n",
    "2. Combine Correlated Variables (Feature Engineering)\n",
    "Principal Component Analysis (PCA): PCA is a dimensionality reduction technique that transforms correlated variables into a smaller set of uncorrelated variables called principal components. These components capture the majority of the variance in the original predictors, which can then be used in the regression model.\n",
    "Factor Analysis: This is another method to combine correlated variables into a smaller number of latent factors, which can be used as predictors in the regression model.\n",
    "Creating Interaction Terms or Summaries: Sometimes, combining correlated variables through interaction terms or creating a composite variable (e.g., an average or weighted sum) may be useful.\n",
    "\n",
    "3. Standardize or Scale Variables\n",
    "Scaling (standardizing) the variables to have a mean of zero and a standard deviation of one can sometimes help in dealing with multicollinearity, especially when variables are on different scales. This ensures that the variance of each predictor is comparable and can help mitigate issues with numerical instability.\n",
    "While scaling doesn't directly resolve high correlation, it can make the model more stable in some cases by addressing numerical issues.\n",
    "\n",
    "4. Use Regularization Techniques\n",
    "Ridge Regression (L2 Regularization): Ridge regression adds a penalty to the loss function that is proportional to the square of the magnitude of the coefficients. This shrinks the coefficients of highly correlated predictors, reducing their impact and mitigating multicollinearity.\n",
    "Lasso Regression (L1 Regularization): Lasso regression adds a penalty proportional to the absolute value of the coefficients. Lasso can set some coefficients exactly to zero, effectively selecting a subset of predictors and removing redundant ones.\n",
    "Both techniques help to deal with multicollinearity by penalizing large coefficients and producing a more stable model.\n",
    "\n",
    "5. Use Variance Inflation Factor (VIF) to Identify and Address Multicollinearity\n",
    "VIF quantifies how much the variance of a coefficient is inflated due to multicollinearity. A VIF greater than 5 or 10 typically indicates problematic multicollinearity.\n",
    "By calculating the VIF for each predictor, you can identify which predictors are highly collinear. You can then consider removing or combining them, or applying regularization techniques.\n",
    "\n",
    "6. Use Stepwise Selection or Feature Selection Methods\n",
    "Stepwise Selection: This technique involves iteratively adding or removing predictors based on criteria such as Akaike Information Criterion (AIC), Bayesian Information Criterion (BIC), or p-values. By doing so, stepwise selection may help to eliminate variables that contribute little or are highly collinear with others.\n",
    "Forward or Backward Selection: These are specific forms of stepwise selection that start with no variables or all variables in the model and add or remove predictors based on their statistical significance.\n",
    "\n",
    "7. Increase Sample Size (if possible)\n",
    "In some cases, multicollinearity issues may be less problematic if you have a larger sample size. A larger dataset can provide more information and reduce the variance in the estimation of coefficients. However, this solution may not always be practical or feasible.\n",
    "\n",
    "8. Consider Non-Linear Models\n",
    "If multicollinearity remains a significant issue despite the steps above, it may be worth considering non-linear modeling techniques, such as decision trees, random forests, or support vector machines (SVMs), that are less sensitive to multicollinearity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4c49e-3804-417a-9b0c-1b85533892e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "13.What are some common techniques for transforming categorical variables for use in regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf935ae-9bf2-449d-ac24-f1788f4634c7",
   "metadata": {},
   "source": [
    "Answer\n",
    "Common Techniques for Transforming Categorical Variables:\n",
    "1. One-Hot Encoding (Dummy Variables)\n",
    "Description: One-hot encoding is a method of converting categorical variables into a series of binary (0/1) variables. Each category is represented by a new binary feature (column), where a \"1\" indicates the presence of the category and a \"0\" indicates its absence.\n",
    "Example: If you have a categorical variable \"Color\" with three categories: Red, Blue, and Green, one-hot encoding would create three binary columns: Color_Red, Color_Blue, and Color_Green.\n",
    "When to Use: One-hot encoding is ideal for nominal variables (categories without any inherent order) and when the number of categories is not too large. It’s commonly used in both linear and logistic regression models.\n",
    "Drawback: One-hot encoding can lead to a large number of columns if the categorical variable has many levels (which can result in a sparse matrix and increased computational cost).\n",
    "\n",
    "2. Label Encoding (Integer Encoding)\n",
    "Description: Label encoding involves assigning a unique integer to each category in a categorical variable. Each category is mapped to a corresponding integer value.\n",
    "Example: If you have a variable \"Size\" with the categories Small, Medium, and Large, label encoding could assign them values like 0, 1, and 2, respectively.\n",
    "When to Use: Label encoding is most useful for ordinal variables (categorical variables with a meaningful order, like Low, Medium, and High) where the numeric relationship between the values has meaning. It’s not suitable for nominal variables where the order doesn’t matter, as it can imply a false ordinal relationship.\n",
    "Drawback: For nominal variables, label encoding can introduce unintended ordinal relationships, which may lead to incorrect interpretations or biased model results in some machine learning algorithms, such as linear regression.\n",
    "\n",
    "3. Ordinal Encoding\n",
    "Description: Ordinal encoding is a specific type of label encoding used for ordinal variables, where the categories have a natural ordering or hierarchy. Unlike simple label encoding, which assigns arbitrary integer values, ordinal encoding respects the ordering of categories.\n",
    "Example: For a \"Rating\" variable with categories \"Poor\", \"Average\", and \"Excellent\", you could assign the values 0, 1, and 2, respectively.\n",
    "When to Use: This is suitable when the categorical variable has an inherent order, such as rating scales or education levels.\n",
    "Drawback: If the model is not aware of the ordinality, it may misinterpret the numerical relationship between the categories. Some models may incorrectly treat the values as continuous, rather than discrete, ordinal data.\n",
    "\n",
    "4. Target Encoding (Mean Encoding)\n",
    "Description: Target encoding involves replacing the categorical variable's values with the mean of the target variable for each category. This method can capture the relationship between the categorical variable and the target variable.\n",
    "Example: If the target variable is \"Sale Price\" and the categorical variable is \"Location\", each category (e.g., \"Urban\", \"Suburban\", \"Rural\") is replaced with the average sale price for that location.\n",
    "When to Use: Target encoding is particularly useful when you have high-cardinality categorical variables and want to encode them with respect to their relationship to the target variable. It's popular in applications like sales prediction or classification tasks where you need to capture information about the target variable.\n",
    "Drawback: Target encoding can lead to overfitting if not handled carefully, especially when there are very few data points per category. It’s essential to use techniques like cross-validation or smoothing to avoid overfitting.\n",
    "\n",
    "5. Binary Encoding\n",
    "Description: Binary encoding is a combination of label encoding and one-hot encoding. It first assigns an integer to each category and then converts that integer into its binary representation. The binary digits are then split across multiple columns.\n",
    "Example: If you have a categorical variable \"Color\" with values Red, Blue, and Green, label encoding might assign Red = 0, Blue = 1, and Green = 2. Then, the binary representations of these values are: Red = 00, Blue = 01, and Green = 10. This would create two binary columns.\n",
    "When to Use: Binary encoding is useful for categorical variables with many levels (high-cardinality variables) as it reduces the dimensionality compared to one-hot encoding, while still capturing some level of information.\n",
    "Drawback: Binary encoding can still result in a high number of features, although it’s generally more efficient than one-hot encoding. It can also be difficult to interpret.\n",
    "\n",
    "6. Frequency or Count Encoding\n",
    "Description: Frequency encoding replaces each category in a categorical variable with the number of times that category appears in the dataset (its frequency) or the total count of occurrences of that category.\n",
    "Example: If the categorical variable \"City\" has values \"New York\", \"Los Angeles\", and \"Chicago\", frequency encoding would replace each city with the number of times it appears in the dataset, such as 500, 300, and 200.\n",
    "When to Use: Frequency encoding is often used when the frequency of a category correlates with the target variable and when you want to capture some information about the distribution of the categories.\n",
    "Drawback: This approach can lose information about the exact category itself, especially when two or more categories have the same frequency.\n",
    "\n",
    "7. Hashing (Feature Hashing)\n",
    "Description: Feature hashing involves applying a hash function to a categorical variable to reduce the dimensionality. The categorical values are hashed into a fixed number of columns, regardless of the number of categories in the original variable.\n",
    "When to Use: Hashing is useful for high-cardinality categorical variables, especially when there are many categories and you want to reduce the dimensionality.\n",
    "Drawback: Hashing can result in hash collisions, where different categories are mapped to the same hashed value, potentially leading to information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf7d2fc-dff3-4eae-8262-8c1c9a2b464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. What is the role of interaction terms in Multiple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba092c6-be29-4317-b39d-0e6329dcb1e0",
   "metadata": {},
   "source": [
    "Answer\n",
    "Role of Interaction Terms in Multiple Linear Regression:\n",
    "\n",
    "Modeling Complex Relationships:\n",
    "Interaction terms help to model non-additive relationships between predictors and the dependent variable. In a standard linear regression, the effect of each predictor is assumed to be constant across all values of other predictors (additive effect). Interaction terms, however, account for cases where the effect of one predictor variable is different at different levels of another predictor.\n",
    "For example, in a regression with variables X1 (years of experience) and X2 (education level), the effect of experience on salary might depend on education. The interaction term would allow the model to account for this varying effect.\n",
    "\n",
    "Improving Model Fit:\n",
    "Including interaction terms can improve model fit by capturing the relationships between predictors that are not purely additive. This can lead to a more accurate representation of the data and improve the predictive power of the model.\n",
    "For example, in a marketing model, the effect of advertising expenditure (X1) and seasonality (X2) on sales (Y) might depend on the interaction between these two variables. The interaction term would allow the model to account for the fact that advertising might be more effective in certain seasons.\n",
    "\n",
    "Capturing Synergistic Effects:\n",
    "Interaction terms help to capture synergistic effects where two predictors jointly produce an effect that is greater or different from the sum of their individual effects. This is particularly important in real-world applications where the combined effect of variables can differ from their individual contributions.\n",
    "For example, the combined effect of age and income on purchasing behavior might be different from the individual effects of age and income alone.\n",
    "\n",
    "Understanding Conditional Effects:\n",
    "Interaction terms allow you to explore how the effect of one independent variable on the dependent variable changes depending on the level of another variable. This is particularly useful for understanding conditional relationships in data.\n",
    "For instance, in a medical study, the effect of diet (X1) on health outcomes (Y) might depend on exercise (X2), meaning the effect of diet on health could be stronger for individuals who exercise regularly.\n",
    "\n",
    "Testing Hypotheses about Relationships:\n",
    "By including interaction terms, you can test specific hypotheses about how different predictors interact with each other. For example, you might hypothesize that the effect of marketing spend (X1) on sales (Y) is different in urban vs. rural areas (X2). The interaction term allows you to explicitly test this hypothesis.\n",
    "\n",
    "Improving Model Interpretation:\n",
    "The inclusion of interaction terms adds complexity to the model, but it can provide more meaningful insights into how predictors influence the outcome variable, especially in cases where the effect of one predictor depends on the value of another.\n",
    "While interaction terms add complexity, they can provide a clearer understanding of how combinations of factors affect the dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa658d3d-bcd7-4d4c-ba15-5ba24748436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. How can the interpretation of intercept differ between Simple and Multiple Linear Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32548cf6-0e33-4ed3-bcb3-5b295b6441ba",
   "metadata": {},
   "source": [
    "Answer:\n",
    "1. Intercept in Simple Linear Regression\n",
    "In Simple Linear Regression, the model consists of a single predictor variable and the dependent variable. The general form of the equation is:\n",
    "Y=β0 +β1X1 +ϵ\n",
    "Where:\n",
    "Y is the dependent variable,\n",
    "X1is the independent (predictor) variable,\n",
    "β0is the intercept (constant),\n",
    "β1is the slope (coefficient of X1),\n",
    "ϵ is the error term.\n",
    "Interpretation of the Intercept (β0):\n",
    "The intercept β0 represents the expected value of the dependent variable Y when the independent variable X1 is zero.\n",
    "In other words, β0 is the predicted value of Y when there is no effect from X1, assuming X1 =0 is a meaningful value in the context of the problem.\n",
    "\n",
    "\n",
    "2.Intercept in Multiple Linear Regression\n",
    "In Multiple Linear Regression, the model includes two or more predictor variables. The general form of the equation is:\n",
    "Y=β0 +β1X1 +β2X2 +⋯+βkXk +ϵ\n",
    "Where:\n",
    "Y is the dependent variable,\n",
    "X1,X2 ,…,Xkare the independent variables (predictors),\n",
    "β0is the intercept (constant),\n",
    "β1 ,β2 ,…,βkare the coefficients of the predictors,\n",
    "ϵ is the error term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a834e33a-f53f-46c7-833c-348f4128a03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "16.- What is the significance of the slope in regression analysis, and how does it affect predictions\u001d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2c308a-37d7-41cf-b117-5385c512c14c",
   "metadata": {},
   "source": [
    "Answer\n",
    "Significance of the Slope in Regression Analysis:\n",
    "\n",
    "Quantifying the Effect of the Predictor:\n",
    "The slope measures the magnitude and direction of the relationship between the independent variable (predictor) and the dependent variable.\n",
    "In simple linear regression, the slope tells you how much the dependent variable Y changes for each one-unit increase in the independent variable X.\n",
    "Example: If the slope is 3, it means that for each one-unit increase in X, the predicted value of Y increases by 3 units. If the slope is -2, it means that for each one-unit increase in X, the predicted value of Y decreases by 2 units.\n",
    "\n",
    "Interpreting the Direction:\n",
    "A positive slope indicates a positive relationship between the predictor and the dependent variable, meaning that as the independent variable increases, the dependent variable also increases.\n",
    "A negative slope indicates a negative relationship, meaning that as the independent variable increases, the dependent variable decreases.\n",
    "Example: In a regression model predicting salary (dependent variable) based on years of experience (independent variable), a positive slope would indicate that as experience increases, salary also tends to increase.\n",
    "\n",
    "Predictive Power:\n",
    "The slope directly impacts predictions in regression analysis. The slope determines how sensitive the predicted value of the dependent variable is to changes in the independent variable.\n",
    "In simple linear regression, the prediction for y is given by:\n",
    "Y=β0 +β1X\n",
    "Where:\n",
    "β0is the intercept,\n",
    "β1is the slope (coefficient of X),\n",
    "X is the independent variable.\n",
    "The slope β1 is the rate at which Y changes as X changes. For example, if β1=5, it means that for every unit increase in X, the predicted value of Y will increase by 5 units.\n",
    "\n",
    "Understanding the Magnitude of Change:\n",
    "The magnitude of the slope (how large or small the coefficient is) indicates how sensitive the dependent variable is to changes in the predictor variable.\n",
    "A large slope indicates a strong relationship between the independent and dependent variables, meaning that small changes in the predictor will cause large changes in the outcome.\n",
    "A small slope indicates a weak relationship, meaning that changes in the predictor have a relatively smaller effect on the outcome.\n",
    "\n",
    "Slope Affects Predictions:\n",
    "The slope directly determines the predicted value of the dependent variable for any given value of the independent variable(s). In regression analysis:\n",
    "\n",
    "Prediction for simple linear regression:\n",
    "Y^ =β0 +β1X\n",
    "Here, Y^ is the predicted value of Y, and β1 determines how much Y will change as X changes.\n",
    "\n",
    "Prediction for multiple linear regression:\n",
    "Y^=β0 +β1X1 +β2X2 +⋯+βkXk\n",
    "​\n",
    " The predicted value of Y is affected by the slopes β1 ,β2 ,…,βk, with each slope representing the change in Y due to a one-unit change in the corresponding Xi, holding all other predictors constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4e8830-48f7-4e07-96b9-c2cded2ed740",
   "metadata": {},
   "outputs": [],
   "source": [
    "17.How does the intercept in a regression model provide context for the relationship between variables\u001d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6995923-e265-4c7b-a1b6-3d675a4d6a7f",
   "metadata": {},
   "source": [
    "Answer\n",
    "The intercept in a regression model represents the expected value of the dependent variable when all independent variables are equal to zero. It provides a baseline or starting point for the model. Here’s how it helps with context:\n",
    "\n",
    "Baseline Value: The intercept is the predicted value of the dependent variable when no independent variables are in play (i.e., when they are zero). For example, in a simple linear regression, the intercept tells you what the output (dependent variable) is when the input (independent variable) is zero.\n",
    "\n",
    "Interpretation Depends on Context: The significance of the intercept depends on whether a zero value for the independent variables is meaningful. If zero is an unrealistic or impossible value (for instance, you’re predicting house prices based on square footage, and zero square footage doesn’t make sense), the intercept might not have a direct practical interpretation. But it still serves as a reference point for understanding the relationship between the variables.\n",
    "\n",
    "Shifting the Line or Curve: In a regression model with more than one independent variable, the intercept shifts the whole regression line or curve up or down. It acts as a vertical offset to align the model with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40be7173-a006-4b33-9e3a-ca52bfa0129b",
   "metadata": {},
   "outputs": [],
   "source": [
    "18.- What are the limitations of using R² as a sole measure of model performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a17f3b0-5ecd-4cc7-bf27-dccea5d4f139",
   "metadata": {},
   "source": [
    "Answer\n",
    "R², or the coefficient of determination, is a commonly used metric to assess how well a regression model fits the data. However, relying on R² alone has several limitations:\n",
    "\n",
    "Doesn’t Account for Model Complexity: R² can increase as more predictors are added to the model, even if those predictors don't improve the model’s actual predictive power. This can give a false sense of a better fit when, in reality, you might just be overfitting the model. Adjusted R² can help mitigate this by penalizing unnecessary predictors.\n",
    "\n",
    "Sensitivity to Outliers: R² is highly sensitive to outliers. A few extreme values can disproportionately influence the R² value, making the model seem better (or worse) than it actually is. This is especially a concern in datasets where outliers may not be indicative of the general pattern.\n",
    "\n",
    "Doesn’t Capture Nonlinear Relationships: R² assumes a linear relationship between the dependent and independent variables. If the true relationship is nonlinear, R² might give a misleading impression of model fit because it doesn't account for more complex patterns.\n",
    "\n",
    "No Information on Model Bias: A high R² does not necessarily mean the model is accurate. It only shows how much of the variance in the dependent variable is explained by the independent variables. It says nothing about whether the model systematically over- or under-predicts.\n",
    "\n",
    "Doesn’t Reflect Prediction Accuracy: A high R² can still correspond to poor predictive performance, especially if the model is overfitting the training data. In such cases, R² might be misleading, as it doesn't directly measure the model's ability to generalize to new, unseen data.\n",
    "\n",
    "Misleading in Certain Contexts: In models where the dependent variable is categorical (e.g., logistic regression), R² doesn't apply. Different performance measures, like accuracy, precision, recall, or AUC, are more appropriate in those cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e8fe20f-4a58-4e2f-b0d0-e42b3e573ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. How would you interpret a large standard error for a regression coefficient?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8fa817-81d2-4eff-a18d-d705f3fe7649",
   "metadata": {},
   "source": [
    "Answer\n",
    "A large standard error for a regression coefficient indicates that the estimate of that coefficient is imprecise or uncertain. Here's how you might interpret it:\n",
    "\n",
    "Imprecise Estimate: The larger the standard error, the wider the range within which the true value of the coefficient could lie. \n",
    "Essentially, you're less confident that the coefficient you’ve estimated is close to the true value.\n",
    "\n",
    "Potential for Insignificant Relationship: A large standard error means that the coefficient might not be significantly different from zero, implying that the independent variable may not have a meaningful impact on the dependent variable. \n",
    "In hypothesis testing, this could lead to a higher p-value, suggesting that you fail to reject the null hypothesis (i.e., that the coefficient equals zero).\n",
    "\n",
    "Multicollinearity Concerns: If the standard error is large, it could signal issues like multicollinearity, where the independent variables in the model are highly correlated with one another. \n",
    "This can make it difficult to isolate the effect of each variable, leading to large standard errors and unreliable coefficient estimates.\n",
    "\n",
    "Sample Size and Variability: A large standard error might also result from having a small sample size or high variability in the data. In such cases, the model is working with less information, leading to less reliable estimates.\n",
    "\n",
    "Model Fit or Misspecification: A large standard error could also suggest that the model might be misspecified. For instance, if the relationship between the independent and dependent variables is not linear but you are using a linear model, this could result in a poor fit and large standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb70f74-b944-42ee-9df8-b3ec7d0f5222",
   "metadata": {},
   "outputs": [],
   "source": [
    "20.- How can heteroscedasticity be identified in residual plots, and why is it important to address it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2147413c-dee0-4943-bf32-67e9cb89911e",
   "metadata": {},
   "source": [
    "Answer\n",
    "Heteroscedasticity refers to the situation where the variance of the errors (residuals) in a regression model is not constant across all levels of the independent variable(s). Identifying and addressing heteroscedasticity is important because it can impact the reliability of statistical tests (like p-values and confidence intervals) and result in inefficient estimates. Here’s how you can identify and why it’s important to address it:\n",
    "\n",
    "Identifying Heteroscedasticity in Residual Plots:\n",
    "Residual plots are one of the most common diagnostic tools for detecting heteroscedasticity. To check for it, you can plot the residuals (the differences between observed and predicted values) on the vertical axis and the fitted (predicted) values or an independent variable on the horizontal axis. Here's what to look for:\n",
    "\n",
    "Funnel or Cone Shape: If the residuals spread out (increase in variability) as the fitted values increase or decrease, that suggests heteroscedasticity. This appears like a funnel, where the residuals are more dispersed at higher or lower levels of the independent variable.\n",
    "\n",
    "Non-Random Patterns: If the residuals show a systematic pattern (e.g., forming a curve or funnel shape) instead of being randomly scattered around zero, it’s an indication of heteroscedasticity. Ideally, residuals should be randomly scattered, indicating constant variance.\n",
    "\n",
    "Uneven Spread: If the residuals are more tightly packed in certain regions of the data (e.g., at the lower or higher end of the independent variable) and more spread out in others, this suggests a violation of the assumption of constant variance.\n",
    "\n",
    "Why It's Important to Address Heteroscedasticity:\n",
    "Inefficient Estimations: When heteroscedasticity is present, the ordinary least squares (OLS) estimates for the regression coefficients remain unbiased, but they are no longer efficient. This means the estimates could have larger standard errors than they would if the variance of the errors were constant, leading to less precise predictions.\n",
    "\n",
    "Invalid Statistical Inference: The presence of heteroscedasticity affects hypothesis tests (e.g., t-tests for individual coefficients) and confidence intervals. Standard errors could be biased, which leads to incorrect p-values and confidence intervals. As a result, you might either incorrectly reject a true null hypothesis (Type I error) or fail to reject a false null hypothesis (Type II error).\n",
    "\n",
    "Misleading Goodness-of-Fit Measures: When the residuals exhibit varying spread, common goodness-of-fit measures like R² may no longer accurately reflect how well the model fits the data, potentially giving misleading results about the model's performance.\n",
    "\n",
    "How to Address Heteroscedasticity:\n",
    "Transformations: One way to address heteroscedasticity is by transforming the dependent variable. Common transformations include using a log or square root transformation to stabilize variance across levels of the independent variable(s).\n",
    "\n",
    "Weighted Least Squares (WLS): If heteroscedasticity is present, using weighted least squares instead of ordinary least squares can adjust for the varying spread in residuals by giving more weight to observations with smaller variance.\n",
    "\n",
    "Robust Standard Errors: Another way to deal with heteroscedasticity is by using heteroscedasticity-robust standard errors, which adjust for the non-constant variance in the error terms without changing the model itself.\n",
    "\n",
    "Reconsider Model Specification: Heteroscedasticity may be a sign that the model is misspecified. It’s worth considering whether the relationship between the dependent and independent variables could be better captured by adding interactions, polynomial terms, or using a different model altogether (e.g., a nonlinear model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15288fe4-4a21-4430-a05d-dea0d34f50b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "21.What does it mean if a Multiple Linear Regression model has a high R² but low adjusted R²?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62abc1fb-6b08-44b4-8c58-e370f0a695ab",
   "metadata": {},
   "source": [
    "Answer\n",
    "If a Multiple Linear Regression model has a high R² but a low adjusted R², it typically indicates that the model might be overfitting the data. Here's what that means in more detail:\n",
    "\n",
    "High R²\n",
    "A high R² suggests that the model explains a large proportion of the variance in the dependent variable. This might make it seem like the model is a good fit to the data.\n",
    "Low Adjusted R²\n",
    "Adjusted R² takes into account the number of predictors in the model, and it adjusts the R² value to penalize the inclusion of irrelevant or unnecessary variables.\n",
    "If adjusted R² is much lower than R², it could mean that some of the independent variables included in the model are not contributing meaningfully to explaining the dependent variable.\n",
    "What It Implies:\n",
    "Overfitting: The model might be overfitting the data. Overfitting occurs when a model becomes too complex by including too many predictors, even if those predictors have little or no real relationship with the dependent variable. This results in a high R², but the adjusted R² penalizes the excessive number of predictors, reflecting that the model is not generalizing well to new, unseen data.\n",
    "\n",
    "Unnecessary Predictors: A high R² paired with a low adjusted R² suggests that the model has likely included some irrelevant or weak predictors. These variables may improve R² slightly but don’t really add predictive power, leading to a reduction in adjusted R².\n",
    "\n",
    "Risk of Misleading Conclusions: A high R² might make the model seem more accurate than it actually is, and without looking at adjusted R², you might be led to believe that the model explains most of the variation in the outcome. However, the low adjusted R² indicates that the model is not well-specified and that a simpler model (with fewer predictors) could potentially perform better.\n",
    "\n",
    "What to Do:\n",
    "Check for Multicollinearity: When you have a large number of predictors, some may be highly correlated with each other, which can inflate R² without improving the model's actual performance. You can check for multicollinearity using Variance Inflation Factor (VIF) and remove highly correlated predictors.\n",
    "\n",
    "Simplify the Model: Try reducing the number of predictors, keeping only those that have a strong theoretical basis or are statistically significant. This should improve the adjusted R² and help reduce overfitting.\n",
    "\n",
    "Cross-Validation: To get a better sense of model performance, consider using cross-validation (e.g., k-fold cross-validation). It helps you evaluate the model's ability to generalize to new data, providing a more reliable assessment than relying on R² alone.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73e5a6-7796-4594-92ef-a9e5dfc8a527",
   "metadata": {},
   "outputs": [],
   "source": [
    "22.Why is it important to scale variables in Multiple Linear Regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6599e1d9-a173-4fcc-9fae-ded5bba05719",
   "metadata": {},
   "source": [
    "Answer\n",
    "Scaling variables in Multiple Linear Regression is important for several reasons, particularly when dealing with models that involve multiple predictors. Here’s why:\n",
    "\n",
    "1. Equal Weight for All Variables:\n",
    "When the predictors have different units or magnitudes (e.g., one variable is measured in thousands and another in percentages), the regression coefficients will reflect the scale of the variables. Without scaling, variables with larger numerical values or wider ranges might dominate the model, even if they aren’t more important in explaining the dependent variable.\n",
    "Scaling ensures that all variables are on the same footing, so the model can fairly evaluate their relative importance.\n",
    "\n",
    "2. Improved Interpretation of Coefficients:\n",
    "In a multiple linear regression model, the coefficients represent the change in the dependent variable for a one-unit change in the independent variable, holding other variables constant. If the variables are on different scales, comparing these coefficients directly can be misleading.\n",
    "By scaling the variables (typically to have a mean of 0 and standard deviation of 1), each coefficient represents the change in the dependent variable for a one standard deviation change in that predictor, making it easier to compare the relative importance of the predictors.\n",
    "\n",
    "3. Faster Convergence in Optimization:\n",
    "Some regression algorithms, especially when using gradient descent or other iterative methods for estimating the coefficients, perform better and converge faster when the predictors are scaled. This is because the optimization algorithm won’t need to adjust for variables with very different scales, which can otherwise slow down the convergence process or lead to numerical instability.\n",
    "\n",
    "4. Regularization:\n",
    "If you are using regularized regression methods like Ridge or Lasso, scaling becomes even more important. These techniques apply penalties (like L2 or L1 regularization) based on the magnitude of the coefficients, and without scaling, variables with larger scales will have a greater influence on the penalty term. This could distort the regularization process and lead to biased results.\n",
    "Scaling ensures that the regularization affects all coefficients equally.\n",
    "\n",
    "5. Multicollinearity:\n",
    "While scaling alone won’t eliminate multicollinearity, it can help identify and mitigate its impact. When predictors are on very different scales, it’s harder to detect and address multicollinearity, where independent variables are highly correlated with each other. Scaling the variables can make it easier to spot potential issues with collinearity.\n",
    "6. Assumptions of Some Algorithms:\n",
    "In some regression models, like Principal Component Regression (PCR) or Partial Least Squares (PLS), scaling is essential because these methods involve dimensionality reduction or projection. Without scaling, the model might focus too much on variables with larger scales and miss the true structure in the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0a983d-e8e4-4919-a9d3-4917e541b8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "23.What is polynomial regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902655db-c536-43e8-a0c1-c52e80e4e79d",
   "metadata": {},
   "source": [
    "Answer\n",
    "Polynomial regression is a type of regression model that fits a polynomial equation to the data, rather than a straight line (as in simple linear regression). It allows the model to capture nonlinear relationships between the independent variable(s) and the dependent variable by including polynomial terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae43d1-a5ae-4112-90d0-ebeb053db2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "24.How does polynomial regression differ from linear regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721748b9-e8cc-45eb-94b7-df40dab8c376",
   "metadata": {},
   "source": [
    "Answer\n",
    "The key difference between polynomial regression and linear regression lies in the relationship they model between the independent variable(s) and the dependent variable. Let’s break down the differences:\n",
    "\n",
    "1. Model Structure\n",
    "Linear Regression:\n",
    "\n",
    "In linear regression, the relationship between the independent variable x and the dependent variable \n",
    "y is assumed to be linear. The model has the form:\n",
    "y=β0 +β1x+ϵ\n",
    "This implies that the change in y is proportional to the change in x, and the relationship is a straight line.\n",
    "Polynomial Regression:\n",
    "\n",
    "Polynomial regression extends linear regression by including higher-order terms (e.g., x2 , x3) to model nonlinear relationships. The model can be written as:\n",
    "y=β0+β1x+β2x2 +β3x3 +⋯+βnxn +ϵ\n",
    "This allows the model to fit curves and capture more complex patterns in the data, making it suitable for situations where the relationship between x and y is not a straight line.\n",
    "\n",
    "2. Fitting the Data\n",
    "Linear Regression:\n",
    "The line fits the data points in a way that minimizes the sum of squared residuals (the difference between the observed values and the predicted values). The result is a straight line that best represents the linear relationship between x and y.\n",
    "Polynomial Regression:\n",
    "Polynomial regression fits a curve to the data by including polynomial terms (like x2 , x3, etc.). This gives the model the flexibility to capture more complex trends, such as quadratic (U-shaped) or cubic curves.\n",
    "\n",
    "3. Flexibility in Modeling Relationships\n",
    "Linear Regression:\n",
    "Suitable when the relationship between the independent and dependent variables is expected to be linear or approximately linear. Linear regression is limited in its ability to capture nonlinear trends.\n",
    "Polynomial Regression:\n",
    "Suitable for modeling nonlinear relationships, such as quadratic, cubic, or higher-order curves. It’s more flexible because it can fit a wide range of curvatures and complex patterns that linear regression cannot.\n",
    "\n",
    "4. Interpretability\n",
    "Linear Regression:\n",
    "In linear regression, the relationship is straightforward and easy to interpret. The coefficient β1\n",
    "​represents the rate of change in y for each unit change in x, and it remains constant across the range of x.\n",
    "Polynomial Regression:\n",
    "Polynomial regression is more difficult to interpret, especially as the degree of the polynomial increases. The coefficients for the higher-order terms (like x2 ,x3) are harder to explain in terms of real-world meaning, as they describe how the effect of x changes at different values of x.\n",
    "\n",
    "5. Risk of Overfitting\n",
    "Linear Regression:\n",
    "Linear regression tends to be less prone to overfitting, especially with a small number of predictors. Overfitting is less of a concern unless you have too many predictors relative to the number of observations.\n",
    "Polynomial Regression:\n",
    "Polynomial regression is more prone to overfitting, especially when using higher-degree polynomials. As the degree of the polynomial increases, the model becomes more flexible and can \"wiggle\" to fit every data point, potentially fitting noise or outliers. This can result in poor generalization to new data.\n",
    "\n",
    "6. Use Cases\n",
    "Linear Regression:\n",
    "Best used when there is a clear linear relationship between the independent and dependent variables, such as predicting sales based on price or predicting height based on age.\n",
    "Polynomial Regression:\n",
    "Best used when there is a nonlinear relationship between the variables, such as modeling the growth of a population over time, where growth might initially accelerate and then decelerate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cbb36c-85de-4720-ab15-5b570273c619",
   "metadata": {},
   "outputs": [],
   "source": [
    "25.When is polynomial regression used ?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c70c3670-e471-41e6-9265-5f61c98118c5",
   "metadata": {},
   "source": [
    "Answer\n",
    "Polynomial regression is used when the relationship between the independent variable(s) and the dependent variable is nonlinear and cannot be accurately captured by a simple straight line. It allows for modeling more complex, curved relationships by introducing higher-order polynomial terms  into the regression model.\n",
    "\n",
    "Here are some specific scenarios where polynomial regression is commonly used:\n",
    "\n",
    "1. Curved Relationships\n",
    "When the relationship between the independent and dependent variables is not linear, but follows a curve instead. For instance:\n",
    "U-shaped or inverted U-shaped relationships: A common example is modeling the effect of study hours on exam performance where performance might initially improve with study time but then start to decrease after reaching an optimal point (a concave curve).\n",
    "S-shaped curves: For example, the growth of a population over time might show an S-curve, where growth accelerates and then slows as it reaches a carrying capacity.\n",
    "\n",
    "2. Improving Fit with Complex Data Patterns\n",
    "When linear regression doesn’t adequately fit the data because the relationship between the variables is more complex, polynomial regression can help by adding polynomial terms to capture these complexities. This is common in situations where you suspect the data might follow a polynomial pattern (quadratic, cubic, etc.) but don’t have prior knowledge of the exact form.\n",
    "\n",
    "3. Modeling Physical Phenomena\n",
    "In physics or engineering, many natural processes and physical phenomena (e.g., velocity-time relationships, chemical reaction rates, or material stress-strain curves) follow nonlinear patterns that can be better captured using polynomial regression.\n",
    "\n",
    "4. Economics and Marketing\n",
    "In economics, the relationship between factors like supply and demand or price and quantity might not be linear, and polynomial regression can help capture the true underlying trend.\n",
    "In marketing, the relationship between advertising spend and sales might be nonlinear. Initially, increasing ads may lead to higher sales, but after a point, further increases may show diminishing returns, which polynomial regression can capture.\n",
    "\n",
    "5. Engineering and Growth Models\n",
    "Engineering data: In some cases, materials' behavior (e.g., stress-strain curves) can be modeled with polynomial equations to capture the complex relationship between different variables.\n",
    "Biological growth: For example, modeling the growth of plants or animals might follow a nonlinear growth curve that polynomial regression can help describe.\n",
    "\n",
    "6. Finance and Investment\n",
    "Investment returns: Some financial models or risk-return relationships might be nonlinear, where returns increase with some investments but start to decrease after reaching a certain threshold. Polynomial regression can help capture such relationships.\n",
    "\n",
    "7. Data with Seasonal or Cyclical Patterns\n",
    "If your data shows cyclical or seasonal behavior that can be represented by a curve, polynomial regression might help. For example, modeling temperature over the course of a year can be well suited for polynomial regression because the relationship follows a periodic curve (e.g., sine-like).\n",
    "\n",
    "8. Trend Detection in Time Series Data\n",
    "In time series data, especially when forecasting future values, polynomial regression can be used to detect and model nonlinear trends over time. For instance, when a time series data set shows rapid growth that decelerates over time (such as population growth), polynomial regression can better capture that pattern than linear regression.\n",
    "\n",
    "9. Fitting Data with Outliers or Noise\n",
    "When you have outliers or noisy data, polynomial regression can sometimes help smooth out the data by fitting a curve that still captures the general pattern without being overly influenced by the extreme values. However, caution is needed because higher-degree polynomials can also amplify noise if overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdff8b9-cb22-4e10-a2cd-43e837acf64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "26.What is the general equation for polynomial regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e1bbad-a1ca-4120-a368-d28bff9ad5a1",
   "metadata": {},
   "source": [
    "Answer\n",
    "The general equation for polynomial regression is an extension of the linear regression equation, where we add polynomial terms to capture nonlinear relationships. The equation for a polynomial regression model of degree n is:\n",
    "y=β0 +β1x+β2x2 +β3x3+⋯+βnxn +ϵ\n",
    "Where:\n",
    "y is the dependent variable (the target value you are trying to predict).\n",
    "x is the independent variable (the predictor or feature).\n",
    "β1,β2,…,βn are the coefficients (parameters) that the model learns during the training process. These coefficients represent the impact of each term on the dependent variable.\n",
    "x2,x3,…,xn are the higher-order polynomial terms that allow the model to capture the curvature and complexity in the data.\n",
    "ϵ is the error term (the residual or noise in the model).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4a5247-56c9-49ff-a779-585fe982d182",
   "metadata": {},
   "outputs": [],
   "source": [
    "27.Can polynomial regression be applied to multiple variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf5a91-c059-4cb8-b195-ea1bfb6ba42e",
   "metadata": {},
   "source": [
    "Answer\n",
    "Yes, polynomial regression can be applied to multiple variables. This is often referred to as multivariable polynomial regression or multivariate polynomial regression. The general idea is the same as in simple polynomial regression, but now you have more than one predictor variable, and you include polynomial terms for all of them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca18e313-4c75-40a4-bdee-d3dcc8641231",
   "metadata": {},
   "outputs": [],
   "source": [
    "28.What are the limitations of polynomial regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b42ac-9f66-477f-9aa6-0de346e04695",
   "metadata": {},
   "source": [
    "Answer\n",
    "Polynomial regression can be a powerful tool for capturing nonlinear relationships between variables, but like any statistical method, it has its limitations. Here are some of the key limitations of polynomial regression:\n",
    "\n",
    "1. Overfitting\n",
    "Overfitting is one of the most significant risks in polynomial regression, especially when using higher-degree polynomials. A higher-degree polynomial can fit the training data very well, but it might also capture noise or outliers in the data rather than the underlying trend. This leads to poor generalization to new, unseen data.\n",
    "The model may become overly complex and show high variance, fitting the training data perfectly while performing poorly on test data.\n",
    "To mitigate overfitting, it's important to use techniques like cross-validation, regularization (such as Lasso or Ridge regression), and selecting an appropriate polynomial degree based on performance.\n",
    "\n",
    "2. Model Complexity\n",
    "As you increase the degree of the polynomial, the number of terms increases, making the model more complex and harder to interpret. For example, a degree 3 polynomial will include x3, x2, and interaction terms, which can become difficult to explain and interpret.\n",
    "Higher-degree polynomials can lead to multicollinearity (when predictors are highly correlated), which makes it harder to determine the individual impact of each predictor.\n",
    "\n",
    "3. Extrapolation Issues\n",
    "Polynomial regression models, especially those with higher-degree polynomials, can behave erratically when making predictions outside the range of the observed data (extrapolation). The model can \"wiggle\" in unpredictable ways and give unrealistic predictions for values of x that were not present in the training data.\n",
    "This can be especially problematic when dealing with high-degree polynomials that might predict extreme values for out-of-sample inputs.\n",
    "4. Multicollinearity\n",
    "Polynomial terms  can introduce high correlation among the predictors. For instance, x and x2\n",
    "are naturally highly correlated. This multicollinearity can lead to unstable estimates of the coefficients, which can make the model sensitive to small changes in the data and lead to inflated standard errors.\n",
    "Multicollinearity can also make it difficult to interpret the individual effect of each predictor.\n",
    "5. Curse of Dimensionality (for Multiple Variables)\n",
    "When polynomial regression is applied to multiple predictors (multivariate polynomial regression), the number of terms increases exponentially as the degree of the polynomial increases. For example, in a two-variable case with a degree of 3, making the model very high-dimensional. This leads to the curse of dimensionality, where the data becomes sparse and harder to model effectively.\n",
    "In such cases, the model becomes more prone to overfitting, and more data is typically needed to obtain meaningful results.\n",
    "\n",
    "6. Interpretability\n",
    "The interpretability of the model decreases as the degree of the polynomial increases. While the linear regression coefficients can be easily interpreted as the effect of each predictor on the dependent variable, polynomial regression coefficients are harder to interpret, especially when interaction terms and higher-degree terms are involved.\n",
    "\n",
    "7. Assumes a Specific Functional Form\n",
    "Polynomial regression assumes that the relationship between the independent variable(s) and the dependent variable can be represented as a polynomial. However, this assumption may not always hold true in real-world data. Sometimes, the true underlying relationship may be better captured by a different model (e.g., logarithmic, exponential, or piecewise relationships).\n",
    "The choice of polynomial degree is also arbitrary and might not necessarily represent the best model for the data. Without proper model selection methods, polynomial regression may not always provide the best fit.\n",
    "\n",
    "8. Computational Cost\n",
    "For very high-degree polynomials or large datasets with many predictors, polynomial regression can become computationally expensive. As the number of polynomial terms grows, the model can take longer to train, especially when the degree of the polynomial and the number of predictors are both high.\n",
    "Additionally, polynomial regression requires calculating the higher-order terms, which may not be efficient for very large datasets.\n",
    "\n",
    "9. Lack of Robustness to Outliers\n",
    "Like many regression techniques, polynomial regression is sensitive to outliers. A single outlier can disproportionately affect the fit of the polynomial, especially if the degree is high. This can distort the curve, leading to inaccurate predictions.\n",
    "Outlier detection and robust regression methods (like Ridge or Lasso) are often needed when applying polynomial regression to data with outliers.\n",
    "\n",
    "10. Limited to Continuous Variables\n",
    "Polynomial regression is generally limited to continuous variables. For categorical variables, you would need to encode them in a way that makes sense for polynomial terms (such as using dummy variables), but this can become more complex and may not always be appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d501c3fd-608e-4e3e-bf34-56e6837351d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "29. What methods can be used to evaluate model fit when selecting the degree of a polynomial ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e33b4-dc56-4c0d-b935-ac6c70f46682",
   "metadata": {},
   "source": [
    "Answer\n",
    "Several methods can use to evaluate model fit when selecting the degree of a polynomial:\n",
    "\n",
    "1. Cross-Validation\n",
    "K-fold Cross-Validation involves splitting the data into K subsets (or folds), training the model on \n",
    "K−1 folds, and testing it on the remaining fold. This process is repeated for each fold, and the results are averaged.\n",
    "Cross-validation helps to evaluate how well the model generalizes to unseen data, which can help you select the degree that minimizes overfitting (high variance) while ensuring good performance.\n",
    "Pros: Provides a more robust estimate of model performance on unseen data.\n",
    "Cons: More computationally expensive, especially with large datasets.\n",
    "How to use it for degree selection:\n",
    "\n",
    "Train polynomial models of different degrees and evaluate their average cross-validation error (e.g., Mean Squared Error or MSE).\n",
    "The degree that minimizes the cross-validation error is usually the best choice.\n",
    "\n",
    "2. Adjusted R²\n",
    "R² (coefficient of determination) measures how much variance in the dependent variable is explained by the model. However, R² always increases as you add more terms to the model, even if the additional terms don't improve the model significantly. This can lead to overfitting when selecting a higher-degree polynomial.\n",
    "Adjusted R² adjusts the R² for the number of predictors in the model, penalizing for adding unnecessary terms. This helps to find the best model that balances goodness of fit with model simplicity.\n",
    "\n",
    "3. Mean Squared Error (MSE) or Root Mean Squared Error (RMSE)\n",
    "MSE measures the average squared difference between the observed and predicted values, and RMSE is simply the square root of MSE. Lower values indicate better fit, but MSE and RMSE are highly sensitive to outliers.\n",
    "These metrics can be used to quantify how well the model performs on test data, allowing you to compare different polynomial degrees.\n",
    "How to use it for degree selection:\n",
    "\n",
    "Compute the MSE or RMSE for different polynomial degrees on the test set (data that was not used in training). The degree that minimizes the MSE or RMSE on the test set is typically the best choice.\n",
    "If MSE decreases too much as the degree increases, this could be a sign of overfitting.\n",
    "\n",
    "4. Akaike Information Criterion (AIC)\n",
    "AIC is a model selection criterion that takes into account the goodness of fit and the number of parameters in the model. It penalizes models with more parameters, so it helps avoid overfitting.\n",
    "Formula for AIC:\n",
    "\n",
    "AIC=2k−2ln( L^)\n",
    "\n",
    "5. Visual Inspection of Residuals\n",
    "Plotting the residuals (the differences between actual and predicted values) can give insight into whether the model is fitting the data well. If residuals show a pattern or trend, this suggests that the model is not capturing the underlying relationship between the variables.\n",
    "For polynomial models, you can look at residual plots to check if the residuals are randomly scattered or if there is any structure left, which might indicate that a higher-degree polynomial could be needed.\n",
    "\n",
    "6. Validation on Holdout or Test Set\n",
    "After training models with different polynomial degrees, evaluate each model's performance on a test set (data that was not used for training). Comparing the test set performance allows you to assess the generalization capability of each model.\n",
    "Use performance metrics such as MSE, RMSE, or R² on the test set to evaluate the model's predictive ability.\n",
    "How to use it for degree selection:\n",
    "\n",
    "The model that performs best on the test set (i.e., lowest MSE or RMSE or highest R²) while avoiding overfitting typically indicates the optimal degree.\n",
    "\n",
    "7. Learning Curves\n",
    "A learning curve shows how model performance changes as you increase the amount of training data. By plotting the training and validation error as a function of the degree of the polynomial, you can identify the point where increasing the degree no longer improves performance.\n",
    "If both the training and validation errors continue to decrease significantly as you increase the degree, it might indicate overfitting. If the validation error stabilizes, this is a good indicator that you've found an optimal degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a563ca2-7212-445b-adaf-a8c321c2b7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "30.Why is visualization important in polynomial regression ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c163a-534f-4da0-8621-7e614cbb522d",
   "metadata": {},
   "source": [
    "Answer\n",
    "Visualization is important in polynomial regression because it helps:\n",
    "\n",
    "Understand the relationship between variables and check if the polynomial model is appropriate.\n",
    "Diagnose overfitting and underfitting by visually inspecting how well the model fits the data at different polynomial degrees.\n",
    "Examine residuals to ensure that the model’s assumptions hold and that it captures the underlying data structure.\n",
    "Identify outliers and influential points that could affect model performance.\n",
    "Evaluate the need for higher-degree polynomials by seeing when the model’s complexity leads to meaningful improvements or excessive oscillations.\n",
    "Compare multiple models and choose the one that balances simplicity and fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e12adb-41f5-4c50-a738-d6f442c8d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "31.- How is polynomial regression implemented in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8ec1fa-9d52-4c7f-b10b-21a6604528b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 91.16159861274987\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Answer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "np.random.seed(0)\n",
    "X = np.random.uniform(0, 10, size=(100, 1))\n",
    "y = 2 * X**2 + 3 * X + 1 + np.random.randn(100, 1) * 10\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly_train = poly.fit_transform(X_train)\n",
    "X_poly_test = poly.transform(X_test)\n",
    "\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly_train, y_train)\n",
    "\n",
    "\n",
    "y_pred = lin_reg.predict(X_poly_test)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "\n",
    "plt.scatter(X_train, y_train, color='red')\n",
    "plt.plot(np.sort(X_train, axis=0), lin_reg.predict(poly.transform(np.sort(X_train, axis=0))), color='blue')\n",
    "plt.title('Polynomial Regression (Degree 2) - Training Set')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(X_test, y_test, color='green')\n",
    "plt.plot(np.sort(X_train, axis=0), lin_reg.predict(poly.transform(np.sort(X_train, axis=0))), color='blue')\n",
    "plt.title('Polynomial Regression (Degree 2) - Test Set')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652ee36c-d1e6-442d-9c32-42007932d7e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
